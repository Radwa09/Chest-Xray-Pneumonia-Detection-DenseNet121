# -*- coding: utf-8 -*-
"""project_DL .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QdYGAMpsfNyisguD0wUzmNjQ6x9VuIfE

1️⃣: Install & Setup Kaggle
"""

!pip install --quiet kaggle

from google.colab import files
files.upload()  # Upload kaggle.json API token

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download Chest X-ray Pneumonia dataset
!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia -q

import zipfile, os
with zipfile.ZipFile("chest-xray-pneumonia.zip", 'r') as z:
    z.extractall("chest_xray_data")

base_dir = "chest_xray_data/chest_xray"
train_dir = os.path.join(base_dir, 'train')
val_dir   = os.path.join(base_dir, 'val')
test_dir  = os.path.join(base_dir, 'test')

print("✅ Dataset downloaded and extracted successfully")
print("Train:", train_dir)
print("Validation:", val_dir)
print("Test:", test_dir)

"""2️⃣: Data Preprocessing & Augmentation"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

IMG_SIZE = (224, 224)

# Training data augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    brightness_range=[0.8,1.2],
    fill_mode='nearest'
)

# Validation & Test data only rescale
val_test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir, target_size=IMG_SIZE, batch_size=32, class_mode='binary'
)

val_generator = val_test_datagen.flow_from_directory(
    val_dir, target_size=IMG_SIZE, batch_size=32, class_mode='binary'
)

test_generator = val_test_datagen.flow_from_directory(
    test_dir, target_size=IMG_SIZE, batch_size=32, class_mode='binary', shuffle=False
)

"""3️⃣: Build Model with Fine-Tuning"""

from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2

# Base model
base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224,224,3))

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.4)(x)
x = Dense(256, activation='relu', kernel_regularizer=l2(1e-4))(x)
predictions = Dense(1, activation='sigmoid')(x)

model = Model(inputs=base_model.input, outputs=predictions)

# Freeze all layers first
for layer in base_model.layers:
    layer.trainable = False

# Fine-tune last 50 layers
for layer in base_model.layers[-50:]:
    layer.trainable = True

# Compile model
model.compile(optimizer=Adam(1e-5), loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

"""4️⃣: Class Weights for Imbalance"""

from sklearn.utils.class_weight import compute_class_weight
import numpy as np

classes = np.unique(train_generator.classes)
weights = compute_class_weight('balanced', classes=classes, y=train_generator.classes)
class_weights = dict(zip(classes, weights))

print("Class weights:", class_weights)

"""5️⃣: Training with Learning Rate Scheduler"""

from tensorflow.keras.callbacks import ReduceLROnPlateau

lr_scheduler = ReduceLROnPlateau(
    monitor='val_loss', factor=0.5, patience=2, verbose=1
)

history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    validation_data=val_generator,
    validation_steps=val_generator.samples // val_generator.batch_size,
    epochs=20,
    class_weight=class_weights,
    callbacks=[lr_scheduler]
)

"""6️⃣: Evaluate Model"""

import numpy as np
from sklearn.metrics import classification_report, roc_auc_score

y_pred_prob = model.predict(test_generator)
y_pred = (y_pred_prob > 0.5).astype(int)

print(classification_report(test_generator.classes, y_pred))
print("ROC-AUC:", roc_auc_score(test_generator.classes, y_pred_prob))

"""7️⃣: Plot Training Loss & Accuracy"""

import matplotlib.pyplot as plt

plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.show()

"""8️⃣: GradCAM Class"""

import tensorflow as tf
import numpy as np
import cv2

class GradCAM:
    def __init__(self, model, layer_name):
        self.model = model
        self.layer_name = layer_name
        self.grad_model = tf.keras.models.Model(
            inputs=model.inputs,
            outputs=[model.get_layer(layer_name).output, model.output]
        )

    def compute_heatmap(self, image_array):
        with tf.GradientTape() as tape:
            conv_outputs, predictions = self.grad_model(image_array)
            loss = predictions[:, 0]

        grads = tape.gradient(loss, conv_outputs)
        pooled_grads = tf.reduce_mean(grads, axis=(0,1,2))
        conv_outputs = conv_outputs[0]
        heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)
        heatmap = np.maximum(heatmap,0)
        heatmap /= (np.max(heatmap)+1e-10)
        return heatmap

"""9️⃣: Gradio GUI"""

!pip install gradio --quiet
import gradio as gr

def gradcam_predict(img):
    img_resized = cv2.resize(np.array(img), (224,224))
    x = img_resized / 255.0
    x = np.expand_dims(x, axis=0)

    pred_prob = model.predict(x)[0][0]
    pred_class = "Pneumonia" if pred_prob > 0.5 else "Normal"

    gradcam = GradCAM(model, layer_name='conv5_block16_concat')
    heatmap = gradcam.compute_heatmap(x)

    img_original = cv2.resize(np.array(img), (224,224))
    heatmap = cv2.resize(heatmap, (img_original.shape[1], img_original.shape[0]))
    heatmap = np.uint8(255*heatmap)
    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
    superimposed = cv2.addWeighted(img_original, 0.6, heatmap, 0.4, 0)

    return superimposed, f"{pred_class} | Confidence: {pred_prob:.2f}"

interface = gr.Interface(
    fn=gradcam_predict,
    inputs=gr.Image(type="pil"),
    outputs=[gr.Image(type="numpy"), gr.Textbox()],
    title="Chest X-ray Pneumonia Detection with GradCAM",
    description="Upload a chest X-ray image to get prediction and GradCAM heatmap"
)

interface.launch()